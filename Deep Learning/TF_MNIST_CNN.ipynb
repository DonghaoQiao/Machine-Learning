{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\qiaod\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "WARNING:tensorflow:From <ipython-input-1-c48877249ea7>:7: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From c:\\users\\qiaod\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From c:\\users\\qiaod\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\users\\qiaod\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\users\\qiaod\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\users\\qiaod\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Datasets(train=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x000001EEB33F25F8>, validation=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x000001EEB85D3B70>, test=<tensorflow.contrib.learn.python.learn.datasets.mnist.DataSet object at 0x000001EEB85D3A20>)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# 加载数据集\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1eec8e85a90>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "batch = mnist.train.images\n",
    "plotData = batch[1]\n",
    "plotData = plotData.reshape(28, 28)\n",
    "plt.gray() # use this line if you don't want to see it in color\n",
    "plt.imshow(plotData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.08\n",
      "step 100, training accuracy 0.9\n",
      "step 200, training accuracy 0.92\n",
      "step 300, training accuracy 0.94\n",
      "step 400, training accuracy 0.96\n",
      "step 500, training accuracy 0.98\n",
      "test accuracy 0.9502\n"
     ]
    }
   ],
   "source": [
    "# 以交互式方式启动session\n",
    "# 如果不使用交互式session，则在启动session前必须\n",
    "# 构建整个计算图，才能启动该计算图\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "\"\"\"构建计算图\"\"\"\n",
    "# 通过占位符来为输入图像和目标输出类别创建节点\n",
    "# shape参数是可选的，有了它tensorflow可以自动捕获维度不一致导致的错误\n",
    "x = tf.placeholder(\"float\", shape=[None, 784])  # 原始输入\n",
    "y = tf.placeholder(\"float\", shape=[None, 10])  # 目标值\n",
    "\n",
    "# 为了不在建立模型的时候反复做初始化操作，\n",
    "# 我们定义两个函数用于初始化\n",
    "def weight_variable(shape):\n",
    "    # 截尾正态分布,stddev是正态分布的标准偏差\n",
    "    initial = tf.truncated_normal(shape=shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "# 卷积核池化,步长为1,0边距\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                          strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "\"\"\"第一层卷积\"\"\"\n",
    "# 由一个卷积和一个最大池化组成。滤波器5x5中算出32个特征，是因为使用32个滤波器进行卷积\n",
    "# 卷积的权重张量形状是[5, 5, 1, 32],1是输入通道的个数，32是输出通道个数\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "# 每一个输出通道都有一个偏置量\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "# 位了使用卷积，必须将输入转换成4维向量，2、3维表示图片的宽、高\n",
    "# 最后一维表示图片的颜色通道（因为是灰度图像所以通道数维1，RGB图像通道数为3）\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "# 第一层的卷积结果,使用Relu作为激活函数\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1))\n",
    "# 第一层卷积后的池化结果\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "\"\"\"第二层卷积\"\"\"\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "\"\"\"全连接层\"\"\"\n",
    "# 图片尺寸减小到7*7，加入一个有1024个神经元的全连接层\n",
    "W_fc1 = weight_variable([7*7*64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "# 将最后的池化层输出张量reshape成一维向量\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "# 全连接层的输出\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "\"\"\"使用Dropout减少过拟合\"\"\"\n",
    "# 使用placeholder占位符来表示神经元的输出在dropout中保持不变的概率\n",
    "# 在训练的过程中启用dropout，在测试过程中关闭dropout\n",
    "keep_prob = tf.placeholder(\"float\")\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "\"\"\"输出层\"\"\"\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "# 模型预测输出\n",
    "y_conv = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2,name='y_conv')\n",
    "\n",
    "# 交叉熵损失\n",
    "cross_entropy = -tf.reduce_sum(y * tf.log(y_conv))\n",
    "\n",
    "# 模型训练,使用AdamOptimizer来做梯度最速下降\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "# 正确预测,得到True或False的List\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_conv, 1),name='y_equal')\n",
    "# 将布尔值转化成浮点数，取平均值作为精确度\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "# 在session中先初始化变量才能在session中调用\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 迭代优化模型\n",
    "for i in range(600):\n",
    "    # 每次取50个样本进行训练\n",
    "    batch = mnist.train.next_batch(50)\n",
    "    if i%100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={\n",
    "            x: batch[0], y: batch[1], keep_prob: 1.0})  # 模型中间不使用dropout\n",
    "        print(\"step %d, training accuracy %g\" % (i, train_accuracy))\n",
    "    train_step.run(feed_dict={x:batch[0], y:batch[1], keep_prob: 0.5})\n",
    "print(\"test accuracy %g\" % accuracy.eval(feed_dict={\n",
    "            x: mnist.test.images, y: mnist.test.labels, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'y_conv:0'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_conv.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 7 variables.\n",
      "Converted 7 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.framework import graph_util\n",
    "\n",
    "output_graph_def = graph_util.convert_variables_to_constants(sess, sess.graph_def, output_node_names=['y_conv'])\n",
    "with tf.gfile.FastGFile('my_model/tfcnnmnist.pb', mode='wb') as f:  # ’wb’中w代表写文件，b代表将数据以二进制方式写入文件。\n",
    "    f.write(output_graph_def.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading the TF graph...\n",
      "Graph Loaded.\n",
      "Collecting all the 'Const' ops from the graph, by running it....\n",
      "Done.\n",
      "Now finding ops in the TF graph that can be dropped for inference\n",
      "Now starting translation to CoreML graph.\n",
      "1/44: Analysing op name: Variable_7 ( type:  Const )\n",
      "2/44: Analysing op name: Variable_7/read ( type:  Identity )\n",
      "3/44: Analysing op name: Variable_6 ( type:  Const )\n",
      "4/44: Analysing op name: Variable_6/read ( type:  Identity )\n",
      "5/44: Analysing op name: dropout/random_uniform/max ( type:  Const )\n",
      "6/44: Analysing op name: dropout/random_uniform/min ( type:  Const )\n",
      "7/44: Analysing op name: dropout/random_uniform/sub ( type:  Sub )\n",
      "8/44: Analysing op name: Placeholder_2 ( type:  Placeholder )\n",
      "Skipping name of placeholder\n",
      "9/44: Analysing op name: Reshape_1/shape ( type:  Const )\n",
      "10/44: Analysing op name: Variable_5 ( type:  Const )\n",
      "11/44: Analysing op name: Variable_5/read ( type:  Identity )\n",
      "12/44: Analysing op name: Variable_4 ( type:  Const )\n",
      "13/44: Analysing op name: Variable_4/read ( type:  Identity )\n",
      "14/44: Analysing op name: Variable_3 ( type:  Const )\n",
      "15/44: Analysing op name: Variable_3/read ( type:  Identity )\n",
      "16/44: Analysing op name: Variable_2 ( type:  Const )\n",
      "17/44: Analysing op name: Variable_2/read ( type:  Identity )\n",
      "18/44: Analysing op name: Reshape/shape ( type:  Const )\n",
      "19/44: Analysing op name: Variable ( type:  Const )\n",
      "20/44: Analysing op name: Variable/read ( type:  Identity )\n",
      "21/44: Analysing op name: Placeholder ( type:  Placeholder )\n",
      "Skipping name of placeholder\n",
      "22/44: Analysing op name: Reshape ( type:  Reshape )\n",
      "23/44: Analysing op name: Conv2D ( type:  Conv2D )\n",
      "24/44: Analysing op name: Relu ( type:  Relu )\n",
      "25/44: Analysing op name: MaxPool ( type:  MaxPool )\n",
      "26/44: Analysing op name: Conv2D_1 ( type:  Conv2D )\n",
      "27/44: Analysing op name: add ( type:  Add )\n",
      "28/44: Analysing op name: Relu_1 ( type:  Relu )\n",
      "29/44: Analysing op name: MaxPool_1 ( type:  MaxPool )\n",
      "30/44: Analysing op name: Reshape_1 ( type:  Reshape )\n",
      "31/44: Analysing op name: MatMul ( type:  MatMul )\n",
      "32/44: Analysing op name: add_1 ( type:  Add )\n",
      "33/44: Analysing op name: Relu_2 ( type:  Relu )\n",
      "34/44: Analysing op name: dropout/div ( type:  RealDiv )\n",
      "35/44: Analysing op name: dropout/Shape ( type:  Shape )\n",
      "36/44: Analysing op name: dropout/random_uniform/RandomUniform ( type:  RandomUniform )\n",
      "37/44: Analysing op name: dropout/random_uniform/mul ( type:  Mul )\n",
      "38/44: Analysing op name: dropout/random_uniform ( type:  Add )\n",
      "39/44: Analysing op name: dropout/add ( type:  Add )\n",
      "40/44: Analysing op name: dropout/Floor ( type:  Floor )\n",
      "41/44: Analysing op name: dropout/mul ( type:  Mul )\n",
      "42/44: Analysing op name: MatMul_1 ( type:  MatMul )\n",
      "43/44: Analysing op name: add_2 ( type:  Add )\n",
      "44/44: Analysing op name: y_conv ( type:  Softmax )\n",
      "Translation to CoreML spec completed. Now compiling and saving the CoreML model.\n",
      "\n",
      " Core ML model generated. Saved at location: my_model/tfcnnmnist.mlmodel \n",
      "\n",
      "Core ML input(s): \n",
      " [name: \"Placeholder_2__0\"\n",
      "type {\n",
      "  multiArrayType {\n",
      "    shape: 1024\n",
      "    dataType: DOUBLE\n",
      "  }\n",
      "}\n",
      ", name: \"Placeholder__0\"\n",
      "type {\n",
      "  multiArrayType {\n",
      "    shape: 784\n",
      "    dataType: DOUBLE\n",
      "  }\n",
      "}\n",
      "]\n",
      "Core ML output(s): \n",
      " [name: \"y_conv__0\"\n",
      "type {\n",
      "  multiArrayType {\n",
      "    shape: 10\n",
      "    dataType: DOUBLE\n",
      "  }\n",
      "}\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "input {\n",
       "  name: \"Placeholder_2__0\"\n",
       "  type {\n",
       "    multiArrayType {\n",
       "      shape: 1024\n",
       "      dataType: DOUBLE\n",
       "    }\n",
       "  }\n",
       "}\n",
       "input {\n",
       "  name: \"Placeholder__0\"\n",
       "  type {\n",
       "    multiArrayType {\n",
       "      shape: 784\n",
       "      dataType: DOUBLE\n",
       "    }\n",
       "  }\n",
       "}\n",
       "output {\n",
       "  name: \"y_conv__0\"\n",
       "  type {\n",
       "    multiArrayType {\n",
       "      shape: 10\n",
       "      dataType: DOUBLE\n",
       "    }\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tfcoreml as tf_converter\n",
    "tf_converter.convert(tf_model_path = 'my_model/tfcnnmnist.pb',\n",
    "                     mlmodel_path = 'my_model/tfcnnmnist.mlmodel',\n",
    "                     output_feature_names = ['y_conv:0'],\n",
    "                     input_name_shape_dict = {'x':[None, 784],'Placeholder_2:0':[1, 1024]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
